import streamlit as st
import json
import os
from glob import glob
from collections import defaultdict
import plotly.graph_objects as go
import pandas as pd
from pathlib import Path

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìˆ˜í•™ ì±„ì  ì‹œìŠ¤í…œ (ê°œì„ íŒ)",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown(u"""
<style>
    /* ë©”ì¸ í—¤ë” */
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 1rem;
    }

    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        padding: 0 28px;
        font-size: 2rem;
        font-weight: 700;
    }

    /* ì„¹ì…˜ í—¤ë” í¬ê¸° ì¡°ì • */
    h3 {
        font-size: 1.5rem !important;
        font-weight: 600 !important;
    }
    h4 {
        font-size: 1.2rem !important;
        font-weight: 500 !important;
    }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        text-align: center;
    }

    /* ë°°ì§€ ìŠ¤íƒ€ì¼ */
    .success-badge {
        background-color: #d4edda;
        color: #155724;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }
    .warning-badge {
        background-color: #fff3cd;
        color: #856404;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }
    .danger-badge {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.25rem 0.5rem;
        border-radius: 0.25rem;
        font-weight: bold;
    }

    /* ì‚¬ì´ë“œë°” í…ìŠ¤íŠ¸ í¬ê¸° */
    .css-1544g2n {
        font-size: 1rem;
    }
</style>
    """, unsafe_allow_html=True)


def find_latest_result_dir():
    """ê°€ì¥ ìµœê·¼ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
    result_dirs = glob("results/new/batch_*")
    if not result_dirs:
        return None
    return max(result_dirs, key=os.path.getmtime)


def load_all_analyses(result_dir):
    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
    analysis_dir = os.path.join(result_dir, 'analysis')
    if not os.path.exists(analysis_dir):
        return []

    analyses = []
    for file in glob(os.path.join(analysis_dir, '*_analysis.json')):
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                analyses.append(data)
        except Exception as e:
            st.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file}")

    return analyses

def load_metadata(problem_id):
    """íŠ¹ì • ë¬¸ì œì˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    metadata_file = f"metadata/{problem_id}_metadata.json"
    if not os.path.exists(metadata_file):
        return None

    try:
        with open(metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        return None

def get_available_batches():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°°ì¹˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    result_dirs = glob("results/new/batch_*")
    return sorted(result_dirs, key=os.path.getmtime, reverse=True)

def get_available_metadata():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° íŒŒì¼ ëª©ë¡"""
    metadata_files = glob("metadata/*_metadata.json")
    return sorted([os.path.basename(f) for f in metadata_files])

def safe_int(value, default=0):
    """ì •ìˆ˜ ë³€í™˜ í•¨ìˆ˜"""
    try:
        return int(value)
    except (ValueError, TypeError):
        return default


with st.sidebar:
    st.markdown("### ğŸ“ ìˆ˜í•™ ì±„ì  ì‹œìŠ¤í…œ (ê°œì„ íŒ)")
    st.markdown("---")

    # ë°°ì¹˜ ì„ íƒ
    st.markdown("### ğŸ“‚ í´ë” ì„ íƒ")
    batches = get_available_batches()
    if batches:
        selected_batch = st.selectbox(
            "ê²°ê³¼ ë””ë ‰í† ë¦¬",
            batches,
            format_func=lambda x: f"{os.path.basename(x)} {'(ìµœì‹ )' if x == batches[0] else ''}",
            label_visibility="collapsed"
        )
    else:
        st.error("ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        selected_batch = None

    st.markdown("---")

    # í•„í„°
    st.markdown("### ğŸ” í•„í„°")
    filter_pass = st.checkbox("PASSë§Œ ë³´ê¸°", value=False)
    filter_fail = st.checkbox("FAILë§Œ ë³´ê¸°", value=False)

    score_range = st.slider(
        "ì ìˆ˜ ë²”ìœ„ (%)",
        min_value=0,
        max_value=100,
        value=(0, 100),
        step=10
    )

    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; font-size: 1rem; color: #888; padding: 0.5rem 0;'>
        Copyright Â© 2025<br>
        ITCEN CLOIT<br>
        All rights reserved.
    </div>
    """, unsafe_allow_html=True)


# ============================================================================ #
# ë©”ì¸ ì˜ì—­
# ============================================================================ #

# í—¤ë”
st.markdown('<div class="main-header">ğŸ“ ìˆ˜í•™ ë¬¸ì œ ìë™ ì±„ì  ì‹œìŠ¤í…œ (ê°œì„ íŒ)</div>', unsafe_allow_html=True)

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs([
    "ğŸ“Š ëŒ€ì‹œë³´ë“œ",
    "ğŸ“ ë¬¸ì œë³„ í•™ìƒí’€ì´ ë¶„ì„",
    "ğŸ’¾ ë¬¸ì œ ë©”íƒ€ë°ì´í„°"
])


# ============================================================================ #
# í™ˆ íƒ­
# ============================================================================ #

with tab1:
    if not selected_batch:
        st.warning("ì„ íƒëœ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.markdown(f"### ğŸ“Š ì „ì²´ í†µê³„ ìš”ì•½")

        # ë°ì´í„° ë¡œë“œ
        analyses = load_all_analyses(selected_batch)

        if not analyses:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # í•„í„° ì ìš©
            initial_filtered_analyses = analyses
            if filter_pass:
                initial_filtered_analyses = [a for a in initial_filtered_analyses if a.get('expected_result') == 'PASS']
            if filter_fail:
                initial_filtered_analyses = [a for a in initial_filtered_analyses if a.get('expected_result') == 'FAIL']

            # ì ìˆ˜ ë²”ìœ„ í•„í„°
            score_filtered_analyses = []
            for a in initial_filtered_analyses:
                final_score = safe_int(a.get('final_score'))
                total_possible = safe_int(a.get('total_possible'))
                if total_possible > 0:
                    percentage = (final_score / total_possible) * 100
                    if score_range[0] <= percentage <= score_range[1]:
                        score_filtered_analyses.append(a)
            
            filtered_analyses = score_filtered_analyses

            # ê¸°ë³¸ í†µê³„
            total_count = len(filtered_analyses)
            pass_count = sum(1 for a in filtered_analyses if a.get('expected_result') == 'PASS')
            fail_count = sum(1 for a in filtered_analyses if a.get('expected_result') == 'FAIL')

            scores = [safe_int(a.get('final_score')) for a in filtered_analyses]
            total_possibles = [safe_int(a.get('total_possible')) for a in filtered_analyses]

            if scores:
                avg_score = sum(scores) / len(scores) if scores else 0
                avg_total = sum(total_possibles) / len(total_possibles) if total_possibles else 0
                avg_percentage = (avg_score / avg_total * 100) if avg_total > 0 else 0
            else:
                avg_score = 0
                avg_total = 0
                avg_percentage = 0

            # ë©”íŠ¸ë¦­ ì¹´ë“œ
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric(label="ğŸ“ ì´ í’€ì´ ìˆ˜", value=total_count)
            with col2:
                st.metric(label="ğŸ“ˆ í‰ê·  ì ìˆ˜", value=f"{avg_score:.1f} / {avg_total:.1f}")
            with col3:
                st.metric(label="âœ… PASS", value=f"{pass_count}ê°œ")
            with col4:
                st.metric(label="âš ï¸ FAIL", value=f"{fail_count}ê°œ")

            st.markdown("---")

            # ì ìˆ˜ ë¶„í¬ ì°¨íŠ¸
            st.markdown("### ğŸ“Š ì ìˆ˜ ë¶„í¬")
            if scores:
                score_ranges = {'90-100%': 0, '80-89%': 0, '70-79%': 0, '60-69%': 0, '60% ë¯¸ë§Œ': 0}
                for score, total in zip(scores, total_possibles):
                    percentage = (score / total * 100) if total > 0 else 0
                    if percentage >= 90: score_ranges['90-100%'] += 1
                    elif percentage >= 80: score_ranges['80-89%'] += 1
                    elif percentage >= 70: score_ranges['70-79%'] += 1
                    elif percentage >= 60: score_ranges['60-69%'] += 1
                    else: score_ranges['60% ë¯¸ë§Œ'] += 1

                fig = go.Figure(data=[go.Bar(
                    x=list(score_ranges.keys()),
                    y=list(score_ranges.values()),
                    text=list(score_ranges.values()),
                    textposition='auto',
                    marker_color=['#28a745', '#5cb85c', '#ffc107', '#fd7e14', '#dc3545']
                )])
                fig.update_layout(xaxis_title="ì ìˆ˜ êµ¬ê°„", yaxis_title="í•™ìƒ ìˆ˜", height=400, showlegend=False)
                st.plotly_chart(fig, width='stretch')

            st.markdown("---")

            # ë¬¸ì œë³„ ì„±ì  í…Œì´ë¸”
            st.markdown("### ğŸ“¢ ë¬¸ì œë³„ ì„±ì ")
            problem_stats = defaultdict(lambda: {'count': 0, 'scores': [], 'total_possibles': []})
            for analysis in filtered_analyses:
                problem_id = analysis.get('problem_id', 'Unknown')
                problem_stats[problem_id]['count'] += 1
                problem_stats[problem_id]['scores'].append(safe_int(analysis.get('final_score')))
                problem_stats[problem_id]['total_possibles'].append(safe_int(analysis.get('total_possible')))

            table_data = []
            for problem_id, stats in sorted(problem_stats.items()):
                if stats['scores']:
                    avg_s = sum(stats['scores']) / stats['count']
                    avg_t = sum(stats['total_possibles']) / stats['count']
                    avg_p = (avg_s / avg_t * 100) if avg_t > 0 else 0
                    table_data.append({
                        'ë¬¸ì œ ID': problem_id,
                        'í’€ì´ ìˆ˜': stats['count'],
                        'í‰ê·  ì ìˆ˜': f"{avg_s:.2f} / {avg_t:.1f}",
                        'í‰ê·  ë¹„ìœ¨': f"{avg_p:.1f}%"
                    })

            if table_data:
                df = pd.DataFrame(table_data)
                st.dataframe(df, width='stretch', hide_index=True)


# ============================================================================ #
# ë¬¸ì œë³„ í•™ìƒí’€ì´ ë¶„ì„ íƒ­
# ============================================================================ #

with tab2:
    if not selected_batch:
        st.warning("ì„ íƒëœ ë°°ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        analyses = load_all_analyses(selected_batch)

        if not analyses:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ë¬¸ì œ ID ëª©ë¡
            problem_ids = sorted(list(set(a.get('problem_id') for a in analyses)))

            selected_problem = st.selectbox(
                "ğŸ“ ë¬¸ì œ ì„ íƒ",
                problem_ids,
                format_func=lambda x: f"ë¬¸ì œ {x}",
                key="problem_selector_update"
            )

            if selected_problem:
                problem_analyses = [a for a in analyses if a.get('problem_id') == selected_problem]

                st.markdown(f"### ğŸ“ ë¬¸ì œ {selected_problem} ìƒì„¸ ë¶„ì„")

                # ë¬¸ì œ ì´ë¯¸ì§€ í‘œì‹œ
                question_image_path = f"resource/question/{selected_problem}.png"
                if os.path.exists(question_image_path):
                    st.markdown("#### ğŸ“· ë¬¸ì œ ì›ë³¸")
                    col1, col2, col3 = st.columns([1, 5, 1])
                    with col2:
                        st.image(question_image_path, width='stretch')
                    st.markdown("---")

                # ê° í’€ì´ ìƒì„¸
                st.markdown(f"### ğŸ‘¥ í•™ìƒ í’€ì´ ëª©ë¡ ({len(problem_analyses)}ê°œ)")

                for idx, analysis in enumerate(problem_analyses, 1):
                    solution_file = analysis.get('solution_file', 'Unknown')
                    final_score = safe_int(analysis.get('final_score'))
                    total_possible = safe_int(analysis.get('total_possible'), default=1)
                    percentage = (final_score / total_possible * 100) if total_possible > 0 else 0
                    if percentage >= 90: emoji = "âœ…"
                    elif percentage >= 70: emoji = "âš ï¸"
                    else: emoji = "âŒ"
                    expander_title = f"ğŸ“„ {solution_file} - {final_score}/{total_possible}ì  ({percentage:.1f}%) {emoji}"

                    with st.expander(expander_title, expanded=(idx == 1)):
                        
                        st.subheader("ğŸ“ í•™ìƒ í’€ì´ ë° AI ê¸°ë³¸ ë¶„ì„")
                        main_col1, main_col2 = st.columns([6, 4])

                        with main_col1:
                            st.markdown("##### í•™ìƒ í’€ì´ ì´ë¯¸ì§€")
                            visualized_image_path = Path(selected_batch) / "visualized" / solution_file
                            if visualized_image_path.exists():
                                with st.expander("BBox ì‹œê°í™” ì´ë¯¸ì§€ ë³´ê¸°/ìˆ¨ê¸°ê¸°", expanded=False):
                                    st.image(str(visualized_image_path), width='stretch')
                            else:
                                original_solve_path = Path("resource/solve") / solution_file
                                if original_solve_path.exists():
                                    st.image(str(original_solve_path), width='stretch')
                                else:
                                    st.warning("í’€ì´ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                        with main_col2:
                            st.markdown("##### AI ì˜¤ë¥˜ ë¶„ì„")
                            error_location = analysis.get('first_error_location')
                            if error_location and error_location.get('has_error'):
                                st.error(
                                    f"**ì˜¤ë¥˜ ë°œìƒ ì§€ì :** Step {error_location.get('error_step_number', 'N/A')}, "
                                    f"Box ID **{error_location.get('error_box_id', 'N/A')}**\n\n"
                                    f"**ì‚¬ìœ :** {error_location.get('reason', 'N/A')}"
                                )
                            else:
                                st.success("**ì˜¤ë¥˜ ë¯¸ë°œê²¬:** AIê°€ í’€ì´ ê³¼ì •ì—ì„œ ëª…ë°±í•œ ì˜¤ë¥˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        st.divider()

                        st.subheader("ğŸ¤– AI ì¢…í•© í‰ê°€")
                        overall_eval = analysis.get('overall_evaluation', {})
                        st.info(f"**ì´í‰ ìš”ì•½:** {overall_eval.get('summary', 'ìš”ì•½ ì •ë³´ ì—†ìŒ')}")
                        
                        eval_col1, eval_col2 = st.columns(2)
                        with eval_col1:
                            with st.container(border=True):
                                st.markdown("##### ê°•ì  ğŸ‘")
                                strengths = overall_eval.get('strengths', [])
                                if strengths:
                                    st.markdown("<ul style='margin-bottom: 0;'>", unsafe_allow_html=True)
                                    for item in strengths: st.markdown(f"<li style='margin-bottom: 0.2em; line-height: 1.2em;'>{item}</li>", unsafe_allow_html=True)
                                    st.markdown("</ul>", unsafe_allow_html=True)
                                else: st.caption("_ë°œê²¬ëœ ê°•ì  ì—†ìŒ_")
                        with eval_col2:
                            with st.container(border=True):
                                st.markdown("##### ì•½ì  ğŸ‘")
                                weaknesses = overall_eval.get('weaknesses', [])
                                if weaknesses:
                                    st.markdown("<ul style='margin-bottom: 0;'>", unsafe_allow_html=True)
                                    for item in weaknesses: st.markdown(f"<li style='margin-bottom: 0.2em; line-height: 1.2em;'>{item}</li>", unsafe_allow_html=True)
                                    st.markdown("</ul>", unsafe_allow_html=True)
                                else: st.caption("_ë°œê²¬ëœ ì•½ì  ì—†ìŒ_")

                        st.divider()

                        st.subheader("ğŸ“Š ë‹¨ê³„ë³„ ì±„ì  ê²°ê³¼")
                        eval_details = analysis.get('step_by_step_evaluation', [])
                        if eval_details:
                            for step in eval_details:
                                status = step.get('status', 'NotAttempted')
                                if status == 'Correct': step_status = "âœ…"
                                elif status in ['Incorrect', 'Partial']: step_status = "âŒ"
                                else: step_status = "âš ï¸"

                                with st.container(border=True):
                                    st.markdown(f"**{step_status} {step.get('step_number')}ë‹¨ê³„: {step.get('step_name', '')}** ({safe_int(step.get('points_earned'))}/{safe_int(step.get('points_possible'))}ì )")
                                    
                                    # LaTeX ë Œë”ë§ ë¡œì§ ê°œì„ 
                                    student_work_latex = step.get('student_work_latex')
                                    if student_work_latex:
                                        with st.container(border=True):
                                            st.caption("í•™ìƒ ë‹µì•ˆ (ì¸ì‹ëœ LaTeX)")
                                            cleaned_latex = student_work_latex.strip()
                                            if cleaned_latex.startswith('$$') and cleaned_latex.endswith('$$'):
                                                cleaned_latex = cleaned_latex[2:-2]
                                            elif cleaned_latex.startswith('$') and cleaned_latex.endswith('$'):
                                                cleaned_latex = cleaned_latex[1:-1]
                                            
                                            # ì´ì¤‘ ë°±ìŠ¬ë˜ì‹œë¥¼ ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œë¡œ ë³€ê²½
                                            cleaned_latex = cleaned_latex.replace('\\\\', '\\')
                                            
                                            try:
                                                st.latex(cleaned_latex)
                                            except Exception as e:
                                                st.warning(f"LaTeX ë Œë”ë§ ì‹¤íŒ¨: {e}")
                                                st.code(student_work_latex, language='latex') # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í‘œì‹œ
                                    elif 'student_work' in step and step['student_work']:
                                        with st.container(border=True):
                                            st.caption("í•™ìƒ ë‹µì•ˆ (ì¸ì‹ëœ í…ìŠ¤íŠ¸)")
                                            st.text(step.get('student_work', ''))

                                    evaluation = step.get('evaluation', 'N/A').replace('\\', '')
                                    st.markdown(f"**í‰ê°€:** {evaluation}")
                                    if status != 'Correct':
                                        feedback = step.get('feedback', 'N/A').replace('\\', '')
                                        st.warning(f"**í”¼ë“œë°±:** {feedback}")
                        else:
                            st.info("ë‹¨ê³„ë³„ ì±„ì  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.divider()

                        st.subheader("ğŸŒ± ê°œì„  ì œì•ˆ ë° ìƒì„¸ í”¼ë“œë°±")
                        sugg_col1, sugg_col2 = st.columns(2)
                        with sugg_col1:
                            st.markdown("##### ê°œì„  ì œì•ˆ")
                            suggestions = analysis.get('improvement_suggestions', [])
                            if suggestions:
                                st.markdown("<ul style='margin-bottom: 0;'>", unsafe_allow_html=True)
                                for suggestion in suggestions:
                                    st.markdown(f"<li style='margin-bottom: 0.2em; line-height: 1.2em;'>{suggestion}</li>", unsafe_allow_html=True)
                                st.markdown("</ul>", unsafe_allow_html=True)
                            else:
                                st.caption("ê°œì„  ì œì•ˆ ì—†ìŒ")

                        with sugg_col2:
                            st.markdown("##### ìƒì„¸ í”¼ë“œë°±")
                            if analysis.get('detailed_feedback'):
                                st.info(analysis['detailed_feedback'].replace('\\\\', '\\'))
                            else:
                                st.caption("ìƒì„¸ í”¼ë“œë°± ì—†ìŒ")

                        if st.checkbox("ì „ì²´ ì±„ì  ê²°ê³¼ ë³´ê¸° (JSON)", key=f"json_{solution_file}"):
                            st.json(analysis)



# ============================================================================ #
# ë©”íƒ€ë°ì´í„° íƒ­
# ============================================================================ #

with tab3:
    st.markdown("### ğŸš€ ë©”íƒ€ë°ì´í„°")

    metadata_files = get_available_metadata()

    if not metadata_files:
        st.error("ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        selected_metadata = st.selectbox(
            "ğŸ“ ë¬¸ì œ ì„ íƒ",
            metadata_files,
            format_func=lambda x: x.replace('_metadata.json', '')
        )

        if selected_metadata:
            problem_id = selected_metadata.replace('_metadata.json', '')
            metadata = load_metadata(problem_id)

            if metadata:
                # ë¬¸ì œ ì´ë¯¸ì§€ í‘œì‹œ
                question_image_path = f"resource/question/{problem_id}.png"
                if os.path.exists(question_image_path):
                    st.markdown("### ğŸ“· ë¬¸ì œ ì´ë¯¸ì§€")
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        st.image(question_image_path, width='stretch')
                    st.markdown("---")

                meta = metadata.get('metadata', {})

                # êµìœ¡ê³¼ì • ì •ë³´
                st.markdown("### ğŸ“š êµìœ¡ê³¼ì • ì •ë³´")
                curriculum = meta.get('curriculum_mapping', {})

                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"**ëŒ€ë‹¨ì›:** {curriculum.get('ëŒ€ë‹¨ì›', 'N/A')}")
                    st.info(f"**ì¤‘ë‹¨ì›:** {curriculum.get('ì¤‘ë‹¨ì›', 'N/A')}")
                with col2:
                    st.info(f"**ì†Œë‹¨ì›:** {curriculum.get('ì†Œë‹¨ì›', 'N/A')}")
                    st.info(f"**ì„±ì·¨ê¸°ì¤€:** {curriculum.get('ì„±ì·¨ê¸°ì¤€_ì½”ë“œ', 'N/A')}")

                st.markdown("---")

                # ë¬¸ì œ ë¶„ì„
                st.markdown("### ğŸ“ ë¬¸ì œ ë¶„ì„")
                problem_analysis = meta.get('problem_analysis', {})

                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"**ë¬¸ì œ ìœ í˜•:** {problem_analysis.get('problem_type', 'N/A')}")
                with col2:
                    st.info(f"**ë‚œì´ë„:** {problem_analysis.get('difficulty', 'N/A')}")

                required_concepts = problem_analysis.get('required_concepts', [])
                if required_concepts:
                    st.info(f"**í•„ìš” ê°œë…:** {', '.join(required_concepts)}")

                if 'problem_intent' in problem_analysis:
                    st.info(f"**ì¶œì œ ì˜ë„:** {problem_analysis['problem_intent']}")

                st.markdown("---")

                # í’€ì´ ë‹¨ê³„
                st.markdown("### ğŸ“‹ í’€ì´ ë‹¨ê³„")
                solution_steps = meta.get('solution_steps', [])

                for step in solution_steps:
                    with st.expander(f"**{step.get('step_number')}ë‹¨ê³„: {step.get('step_name')}** (ë°°ì : {step.get('points')}ì )"):
                        st.markdown(f"**ì„¤ëª…:** {step.get('description')}")
                        st.markdown(f"**í•µì‹¬ ê°œë…:** {step.get('key_concept')}")
                        st.markdown(f"**ê¸°ëŒ€ í–‰ë™:** {step.get('expected_action')}")

                        common_errors = step.get('common_errors', [])
                        if common_errors:
                            st.warning("**í”í•œ ì˜¤ë¥˜:**")
                            for error in common_errors:
                                st.write(f"- {error}")

                st.markdown("---")

                # JSON ì›ë³¸
                if st.button("ğŸ“„ JSON ì›ë³¸ ë³´ê¸°"):
                    st.json(metadata)


# ============================================================================ #
# í‘¸í„°
# ============================================================================ #

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9rem;'>
    Copyright Â© 2025ITCEN CLOIT. All rights reserved.
</div>
""", unsafe_allow_html=True)


if __name__ == "__main__":
    import sys
    import subprocess

    if len(sys.argv) == 1:
        subprocess.run([
            "streamlit", "run", __file__,
            "--server.headless", "true"
        ])